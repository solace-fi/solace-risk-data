{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solace Relativity v1.0 - Build Relativity and EJ Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read exploits db, use derivedValueIndicators and build data-values files and relativity scores, build expert-judgement template files, and build expert-judgement weighting files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exploit damage ratio:  0.24146191913870418\n",
      "Data values json files created in governance directory\n",
      "Initializing EJ files 1...\n",
      "EJ Submitter1 created in governance directory\n",
      "Initializing EJ files 2...\n",
      "EJ Submitter2 created in governance directory\n",
      "Initializing EJ files 3...\n",
      "EJ Submitter3 created in governance directory\n",
      "\n",
      "Relativities have been initialed to 1. Update files in governance directory to incorporate expert judgement into realativity scoring.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "NUMBEROFEJSUBMITTERS = 3\n",
    "\n",
    "#WIP\n",
    "\n",
    "## Load Exploits, Protocols(tbd), and mappingTables (transactional and temporal) \n",
    "# TODO - next version, find each predictor columns and create mapping table entries\n",
    "exploitsDf = pd.read_csv('../exploits/historical_exploits.csv')\n",
    "f = open('../governance/reference/mappingTablesSolace.json')\n",
    "lookupTables = json.loads(f.read())\n",
    "f.close()\n",
    "\n",
    "# Init dfs for lookup tables\n",
    "tvlSolaceLookupTable = pd.DataFrame(lookupTables['tvlSolaceLookup'])\n",
    "auditsSolaceLookupTable = pd.DataFrame(lookupTables['auditSolaceLookup'])\n",
    "oraclesSolaceLookupTable = lookupTables['oracleSolaceLookup'] # just values, not mappings: yes/no/unknown\n",
    "# TODO - category mapping ??\n",
    "\n",
    "# Calc Exploit Damage ratio\n",
    "exploitsDf['tvlPreExploit'] = exploitsDf['tvlPreExploit'] / 10 # confirm wtih Tim\n",
    "exploitsDf['exploitDamage'] = exploitsDf['loss'] / exploitsDf['tvlPreExploit']\n",
    "#exploitsDf['exploitDamage']= exploitsDf['exploitDamage'].astype(object).replace(np.nan, 'null')\n",
    "\n",
    "# Calc time to exploit\n",
    "exploitsDf[['launchDate','exploitDate']] = exploitsDf[['launchDate','exploitDate']].apply(pd.to_datetime) #if conversion required\n",
    "exploitsDf['timeToExploit'] = (exploitsDf['exploitDate'] - exploitsDf['launchDate']).dt.days\n",
    "exploitsDf['timeToExploit'] = exploitsDf['timeToExploit'].astype(object).replace(np.nan, 'null')\n",
    "\n",
    "# Derive tvlSolace column\n",
    "def lookup_tvlSolace(tvl):\n",
    "    if math.isnan(tvl):\n",
    "        return 'null'\n",
    "    match = (tvlSolaceLookupTable['lowerLimit'] <= tvl) & (tvlSolaceLookupTable['upperLimit'] > tvl)\n",
    "    tvlOut = tvlSolaceLookupTable['tvlSolace'][match]\n",
    "    return tvlOut.values[0]\n",
    "exploitsDf['tvlSolace'] = exploitsDf['tvlPreExploit'].apply(lookup_tvlSolace)\n",
    "\n",
    "# Derive auditSolace column\n",
    "def lookup_auditSolace(audits):\n",
    "    if math.isnan(audits):\n",
    "        return 'Unknown'\n",
    "    match = (auditsSolaceLookupTable['auditsOg'] == audits)\n",
    "    auditsOut = auditsSolaceLookupTable['auditSolace'][match]\n",
    "    return auditsOut.values[0]\n",
    "exploitsDf['auditSolace'] = exploitsDf['audits'].apply(lookup_auditSolace)\n",
    "\n",
    "# Derive oracleSolace column\n",
    "def lookup_oracleSolace(oracles,catalog):\n",
    "    if pd.isna(catalog):\n",
    "        return 'Unknown'\n",
    "    elif pd.isna(oracles):\n",
    "        return 'No'\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "exploitsDf['oracleSolace'] = exploitsDf.apply(lambda x: lookup_oracleSolace(x.oracles, x.category), axis=1)\n",
    "\n",
    "# Create columns for use in one way calcs\n",
    "exploitsDf['tvlAvgDamage'] = exploitsDf.groupby(['tvlSolace'])['exploitDamage'].transform('mean')\n",
    "exploitsDf['auditAvgDamage'] = exploitsDf.groupby(['auditSolace'])['exploitDamage'].transform('mean')\n",
    "exploitsDf['oracleAvgDamage'] = exploitsDf.groupby(['oracleSolace'])['exploitDamage'].transform('mean')\n",
    "\n",
    "averageDamage = exploitsDf['exploitDamage'].mean()\n",
    "\n",
    "exploitsDf['tvlDamageRatio'] = exploitsDf['tvlAvgDamage'] / averageDamage\n",
    "exploitsDf['auditDamageRatio'] = exploitsDf['auditAvgDamage'] / averageDamage\n",
    "exploitsDf['oracleDamageRatio'] = exploitsDf['oracleAvgDamage'] / averageDamage\n",
    "\n",
    "print('Average exploit damage ratio: ',averageDamage)\n",
    "\n",
    "# Create one way 'tables', separate for readability \n",
    "# TVL\n",
    "tvlOneWay = pd.DataFrame()\n",
    "tvlOneWay['damageRatio'] = exploitsDf['tvlDamageRatio'].unique()\n",
    "tvlOneWay['tvlSolace'] =exploitsDf['tvlSolace'].unique()\n",
    "tvlOneWay['avgDamage'] = exploitsDf['tvlAvgDamage'].unique()\n",
    "\n",
    "# AUDITS\n",
    "auditOneWay = pd.DataFrame()\n",
    "auditOneWay['damageRatio'] = exploitsDf['auditDamageRatio'].unique()\n",
    "auditOneWay['auditSolace'] = exploitsDf['auditSolace'].unique()\n",
    "auditOneWay['avgDamage'] = exploitsDf['auditAvgDamage'].unique()\n",
    "\n",
    "# ORACLES\n",
    "oracleOneWay = pd.DataFrame()\n",
    "oracleOneWay['damageRatio'] = exploitsDf['oracleDamageRatio'].unique()\n",
    "oracleOneWay['oracleSolace'] =exploitsDf['oracleSolace'].unique()\n",
    "oracleOneWay['avgDamage'] = exploitsDf['oracleAvgDamage'].unique()\n",
    "\n",
    "def write_json(df, fileName, drop):\n",
    "    if drop == True:\n",
    "        df.drop(['avgDamage'], axis=1, inplace=True)\n",
    "    data = df.to_json(orient='columns')\n",
    "    os.makedirs(os.path.dirname(fileName), exist_ok=True)\n",
    "    with open(fileName, 'w') as outfile:\n",
    "        outfile.write(data)\n",
    "\n",
    "write_json(pd.merge(tvlOneWay, tvlSolaceLookupTable, how=\"right\", on='tvlSolace'), '../governance/data-values/tvlDataValues.json', True)\n",
    "write_json(pd.merge(auditOneWay, auditsSolaceLookupTable, how=\"right\", on='auditSolace'), '../governance/data-values/auditDataValues.json', True)\n",
    "write_json(oracleOneWay, '../governance/data-values/oracleDataValues.json', True)\n",
    "\n",
    "print(\"Data values json files created in governance directory\")\n",
    "\n",
    "# Initialize EJ directories, files and weightings\n",
    "def initialize_ejs(df):\n",
    "    for i in df['damageRatio']:\n",
    "        df['damageRatio'] = 1\n",
    "    return df\n",
    "\n",
    "# EJ weighting files\n",
    "def create_weights(predictor):\n",
    "    weightingsTemplate = '{\"' + predictor + 'Basis\": {\"1\": \"data\"},\"weight\": {\"1\": 1}}'\n",
    "    weightingsTemplateJson = json.loads(weightingsTemplate)\n",
    "    weightingsTemplateDf = pd.DataFrame(weightingsTemplateJson)\n",
    "    write_json(weightingsTemplateDf, '../governance/weightings/'+predictor+'Weighting.json', False)\n",
    "create_weights('audit')\n",
    "create_weights(\"oracle\")\n",
    "create_weights(\"tvl\")\n",
    "\n",
    "for i in range(NUMBEROFEJSUBMITTERS):\n",
    "    print(\"Initializing EJ files \" + str(i+1) + \"...\")\n",
    "    write_json(initialize_ejs(tvlOneWay), '../governance/expert-judgement/' + str(i+1) + '/ejTvlDataValues.json', False)\n",
    "    write_json(initialize_ejs(oracleOneWay), '../governance/expert-judgement/' + str(i+1) + '/ejOracleDataValues.json', False)\n",
    "    write_json(initialize_ejs(auditOneWay), '../governance/expert-judgement/' + str(i+1) + '/ejAuditDataValues.json', False)\n",
    "    print(\"EJ Submitter\" + str(i+1) + \" created in governance directory\")\n",
    "    # Create weighting files per predictor with basis and each expert   \n",
    "\n",
    "print(\"\\nRelativities have been initialed to 1. Update files in governance directory to incorporate expert judgement into realativity scoring.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "413cd85ab13ac62721d0f2c5aa8745784a29b6d09b4bf6a7b76b2766b50fd579"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
