{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solace Relativity v1.0 - Build Relativity and EJ Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read exploits db, use derivedValueIndicators and build data-values files and relativity scores, build expert-judgement template files, and build expert-judgement weighting files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exploit damage ratio:  0.24146191913870418\n",
      "Data values json files created in governance directory\n",
      "Initializing EJ files 1...\n",
      "EJ Submitter1 created in governance directory\n",
      "Initializing EJ files 2...\n",
      "EJ Submitter2 created in governance directory\n",
      "Initializing EJ files 3...\n",
      "EJ Submitter3 created in governance directory\n",
      "\n",
      "Relativities have been initialed to 1. Update files in governance directory to incorporate expert judgement into realativity scoring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haral\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "NUMBEROFEJSUBMITTERS = 3\n",
    "\n",
    "#WIP\n",
    "\n",
    "## Load Exploits, Protocols(tbd), and mappingTables (transactional and temporal) \n",
    "# TODO - next version, find each predictor columns and create mapping table entries\n",
    "temporalDb=pd.read_excel('../temporalDB/TemporalDataset.xlsx')\n",
    "exploitsDf = pd.read_csv('../exploits/historical_exploits.csv')\n",
    "f = open('../governance/reference/mappingTablesSolace.json')\n",
    "lookupTables = json.loads(f.read())\n",
    "f.close()\n",
    "\n",
    "# Init dfs for lookup tables\n",
    "tvlSolaceLookupTable = pd.DataFrame(lookupTables['tvlSolaceLookup'])\n",
    "auditsSolaceLookupTable = pd.DataFrame(lookupTables['auditSolaceLookup'])\n",
    "oraclesSolaceLookupTable = lookupTables['oracleSolaceLookup'] # just values, not mappings: yes/no/unknown\n",
    "categorySolaceLookupTable=pd.DataFrame(lookupTables['categorySolaceLookup'])\n",
    "\n",
    "\n",
    "# TODO - category mapping ??\n",
    "\n",
    "# Calc Exploit Damage ratio\n",
    "exploitsDf['tvlPreExploit'] = exploitsDf['tvlPreExploit'] / 10 # confirm wtih Tim\n",
    "exploitsDf['exploitDamage'] = exploitsDf['loss'] / exploitsDf['tvlPreExploit']\n",
    "#exploitsDf['exploitDamage']= exploitsDf['exploitDamage'].astype(object).replace(np.nan, 'null')\n",
    "\n",
    "# Calc time to exploit\n",
    "exploitsDf[['launchDate','exploitDate']] = exploitsDf[['launchDate','exploitDate']].apply(pd.to_datetime) #if conversion required\n",
    "exploitsDf['timeToExploit'] = (exploitsDf['exploitDate'] - exploitsDf['launchDate']).dt.days\n",
    "exploitsDf['timeToExploit'] = exploitsDf['timeToExploit'].astype(object).replace(np.nan, 'null')\n",
    "\n",
    "\n",
    "\n",
    "def lookup_categorySolace(category):\n",
    "    if pd.isna(category):\n",
    "        return 'Unknown'\n",
    "    elif category not in list(categorySolaceLookupTable['category']):\n",
    "        return 'other'\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Derive tvlSolace column\n",
    "def lookup_tvlSolace(tvl):\n",
    "    if math.isnan(tvl):\n",
    "        return 'null'\n",
    "    match = (tvlSolaceLookupTable['lowerLimit'] <= tvl) & (tvlSolaceLookupTable['upperLimit'] > tvl)\n",
    "    tvlOut = tvlSolaceLookupTable['tvlSolace'][match]\n",
    "    return tvlOut.values[0]\n",
    "\n",
    "\n",
    "# Derive auditSolace column\n",
    "def lookup_auditSolace(audits):\n",
    "    if math.isnan(audits):\n",
    "        return 'Unknown'\n",
    "    match = (auditsSolaceLookupTable['auditsOg'] == audits)\n",
    "    auditsOut = auditsSolaceLookupTable['auditSolace'][match]\n",
    "    return auditsOut.values[0]\n",
    "\n",
    "\n",
    "# Derive oracleSolace column\n",
    "def lookup_oracleSolace(oracles,catalog):\n",
    "    if pd.isna(catalog):\n",
    "        return 'Unknown'\n",
    "    elif pd.isna(oracles):\n",
    "        return 'No'\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "# Reminder-add categorySolace to exploits too\n",
    "\n",
    "#Solace judgement\n",
    "\n",
    "exploitsDf['tvlSolace'] = exploitsDf['tvlPreExploit'].apply(lookup_tvlSolace)\n",
    "temporalDb['tvlSolace'] = temporalDb['tvl'].apply(lookup_tvlSolace)\n",
    "exploitsDf['auditSolace'] = exploitsDf['audits'].apply(lookup_auditSolace)\n",
    "temporalDb['auditSolace'] = temporalDb['audits'].apply(lookup_auditSolace)            \n",
    "exploitsDf['oracleSolace'] = exploitsDf.apply(lambda x: lookup_oracleSolace(x.oracles, x.category), axis=1)\n",
    "temporalDb['oracleSolace'] = temporalDb.apply(lambda x: lookup_oracleSolace(x.oracles, x.tags), axis=1)\n",
    "\n",
    "\n",
    "# Create columns for use in one way calcs\n",
    "exploitsDf['tvlAvgDamage'] = exploitsDf.groupby(['tvlSolace'])['exploitDamage'].transform('mean')\n",
    "exploitsDf['auditAvgDamage'] = exploitsDf.groupby(['auditSolace'])['exploitDamage'].transform('mean')\n",
    "exploitsDf['oracleAvgDamage'] = exploitsDf.groupby(['oracleSolace'])['exploitDamage'].transform('mean')\n",
    "\n",
    "averageDamage = exploitsDf['exploitDamage'].mean()\n",
    "\n",
    "exploitsDf['tvlDamageRatio'] = exploitsDf['tvlAvgDamage'] / averageDamage\n",
    "exploitsDf['auditDamageRatio'] = exploitsDf['auditAvgDamage'] / averageDamage\n",
    "exploitsDf['oracleDamageRatio'] = exploitsDf['oracleAvgDamage'] / averageDamage\n",
    "\n",
    "print('Average exploit damage ratio: ',averageDamage)\n",
    "\n",
    "# Create one way 'tables', separate for readability \n",
    "# TVL\n",
    "tvlOneWay = pd.DataFrame()\n",
    "tvlOneWay['damageRatio'] = exploitsDf['tvlDamageRatio'].unique()\n",
    "tvlOneWay['tvlSolace'] =exploitsDf['tvlSolace'].unique()\n",
    "tvlOneWay['avgDamage'] = exploitsDf['tvlAvgDamage'].unique()\n",
    "\n",
    "# AUDITS\n",
    "auditOneWay = pd.DataFrame()\n",
    "auditOneWay['damageRatio'] = exploitsDf['auditDamageRatio'].unique()\n",
    "auditOneWay['auditSolace'] = exploitsDf['auditSolace'].unique()\n",
    "auditOneWay['avgDamage'] = exploitsDf['auditAvgDamage'].unique()\n",
    "\n",
    "# ORACLES\n",
    "oracleOneWay = pd.DataFrame()\n",
    "oracleOneWay['damageRatio'] = exploitsDf['oracleDamageRatio'].unique()\n",
    "oracleOneWay['oracleSolace'] =exploitsDf['oracleSolace'].unique()\n",
    "oracleOneWay['avgDamage'] = exploitsDf['oracleAvgDamage'].unique()\n",
    "\n",
    "def write_json(df, fileName, drop):\n",
    "    if drop == True:\n",
    "        df.drop(['avgDamage'], axis=1, inplace=True)\n",
    "    data = df.to_json(orient='columns')\n",
    "    os.makedirs(os.path.dirname(fileName), exist_ok=True)\n",
    "    with open(fileName, 'w') as outfile:\n",
    "        outfile.write(data)\n",
    "\n",
    "write_json(pd.merge(tvlOneWay, tvlSolaceLookupTable, how=\"right\", on='tvlSolace'), '../governance/data-values/tvlDataValues.json', True)\n",
    "write_json(pd.merge(auditOneWay, auditsSolaceLookupTable, how=\"right\", on='auditSolace'), '../governance/data-values/auditDataValues.json', True)\n",
    "write_json(oracleOneWay, '../governance/data-values/oracleDataValues.json', True)\n",
    "\n",
    "print(\"Data values json files created in governance directory\")\n",
    "\n",
    "# Initialize EJ directories, files and weightings\n",
    "def initialize_ejs(df):\n",
    "    for i in df['damageRatio']:\n",
    "        df['damageRatio'] = 1\n",
    "    return df\n",
    "\n",
    "# EJ weighting files\n",
    "def create_weights(predictor):\n",
    "    weightingsTemplate = '{\"' + predictor + 'Basis\": {\"1\": \"data\",\"2\":\"Ej1\"},\"weight\": {\"1\": 0.75, \"2\":0.25}}'\n",
    "    weightingsTemplateJson = json.loads(weightingsTemplate)\n",
    "    weightingsTemplateDf = pd.DataFrame(weightingsTemplateJson)\n",
    "    write_json(weightingsTemplateDf, '../governance/weightings/'+predictor+'Weighting.json', False)\n",
    "    \n",
    "create_weights('audit')\n",
    "create_weights(\"oracle\")\n",
    "create_weights(\"tvl\")\n",
    "create_weights(\"category\")\n",
    "\n",
    "for i in range(NUMBEROFEJSUBMITTERS):\n",
    "    print(\"Initializing EJ files \" + str(i+1) + \"...\")\n",
    "    write_json(initialize_ejs(tvlOneWay), '../governance/expert-judgement/' + str(i+1) + '/ejTvlDataValues.json', False)\n",
    "    write_json(initialize_ejs(oracleOneWay), '../governance/expert-judgement/' + str(i+1) + '/ejOracleDataValues.json', False)\n",
    "    write_json(initialize_ejs(auditOneWay), '../governance/expert-judgement/' + str(i+1) + '/ejAuditDataValues.json', False)\n",
    "    print(\"EJ Submitter\" + str(i+1) + \" created in governance directory\")\n",
    "    # Create weighting files per predictor with basis and each expert   \n",
    "\n",
    "print(\"\\nRelativities have been initialed to 1. Update files in governance directory to incorporate expert judgement into realativity scoring.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Data relativities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data values\n",
    "def open_data(file):\n",
    "    Data = open(file)\n",
    "    lookupTables = json.loads(Data.read())\n",
    "    Data.close()\n",
    "    return lookupTables\n",
    "\n",
    "def add_column(file,key,database,merger):\n",
    "    lookup=open_data(file)\n",
    "    attributeSolaceRelativity=lookup[key]\n",
    "    attributeFrame=pd.DataFrame(attributeSolaceRelativity)\n",
    "    combinedAuditTable1=pd.merge(database,attributeFrame,left_on=merger, right_on=merger, how='left')\n",
    "    return combinedAuditTable1\n",
    "\n",
    "def calc_finalRelativity(weightLookup,combinedtable2,column1,column2,key,key_weight):\n",
    "    lookupTable=open_data(weightLookup)\n",
    "    #lookupTable=open_data('../governance/weightings/auditWeighting.json')\n",
    "    lookupFrame=pd.DataFrame(lookupTable)\n",
    "    data_weight=lookupFrame[lookupFrame[key_weight]=='data']['weight']\n",
    "    solaceRM_weight=lookupFrame[lookupFrame[key_weight]=='Ej1']['weight']\n",
    "    combinedtable2[key]=(column1*data_weight.values)+(column2*solaceRM_weight.values) #+(column1*solaceRM_weight.values)+(column2*solaceRM_weight.values)\n",
    "    return combinedtable2\n",
    "\n",
    "def aggregateTables(weightLookup,file,file2,key,key1,key2,database,merger,key_weight):\n",
    "    # Add audit Relativities\n",
    "    column_test=add_column(file,key,database,merger)\n",
    "    column_test2=add_column(file2,key,column_test,merger)\n",
    "    column_test3=calc_finalRelativity(weightLookup,column_test2,column_test2[key1],column_test2[key2],key,key_weight)\n",
    "    return column_test3\n",
    "\n",
    "AuditRelativityColumns=aggregateTables('../governance/weightings/auditWeighting.json','../governance/data-values/auditRelativities.json','../governance/expert-judgement/solaceRM/ejAuditDataValues.json','auditSolaceRelativities','relativityAuditData','relativityAuditEj1',temporalDb,'auditSolace','auditBasis')\n",
    "TVLRelativityColumns=aggregateTables('../governance/weightings/tvlWeighting.json','../governance/data-values/tvlRelativities.json','../governance/expert-judgement/solaceRM/ejTvlDataValues.json','tvlSolaceRelativities','relativityTvlData','relativityTvlEj1',AuditRelativityColumns,'tvlSolace','tvlBasis')\n",
    "OracleRelativityColumns=aggregateTables('../governance/weightings/oracleWeighting.json','../governance/data-values/oracleRelativities.json','../governance/expert-judgement/solaceRM/ejOracleDataValues.json','oracleSolaceRelativities','relativityOracleData','relativityOracleEj1',TVLRelativityColumns,'oracleSolace','oracleBasis')\n",
    "CategoryRelativityColumns=aggregateTables('../governance/weightings/categoryWeighting.json','../governance/data-values/categoryRelativities.json','../governance/expert-judgement/solaceRM/ejCategoryDataValues.json','categorySolaceRelativities','relativityCategoryData','relativityCategoryEj1',OracleRelativityColumns,'categorySolace','categoryBasis')\n",
    "\n",
    "CategoryRelativityColumns['finalRelativity']=CategoryRelativityColumns['auditSolaceRelativities']*CategoryRelativityColumns['tvlSolaceRelativities']*CategoryRelativityColumns['oracleSolaceRelativities']*CategoryRelativityColumns['categorySolaceRelativities']\n",
    "#protocolMap=CategoryRelativityColumns.filter(['appId','tier','category'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map protocols to tiers based on final Relativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelativityTable=pd.read_json('../governance/reference/relativityTable.json')\n",
    "\n",
    "\n",
    "def tiers(relativities,RelativityTable):\n",
    "    min_val=RelativityTable['minRelativity']\n",
    "    max_val=RelativityTable['maxRelativity']\n",
    "    tier=RelativityTable['tier']\n",
    "    riskTiers=[]\n",
    "    for value in relativities:\n",
    "        if value<max_val[0] and value>min_val[0]:\n",
    "                riskTiers.append(tier[0])\n",
    "        elif value<max_val[1] and value>min_val[1]:\n",
    "                riskTiers.append(tier[1])\n",
    "        elif value<max_val[2] and value>min_val[2]:\n",
    "                riskTiers.append(tier[2])\n",
    "        else:\n",
    "                riskTiers.append(tier[3])\n",
    "    return riskTiers\n",
    "\n",
    "\n",
    "\n",
    "protocolRelativity=CategoryRelativityColumns['finalRelativity']\n",
    "Risk_Tiers=tiers(protocolRelativity,RelativityTable)\n",
    "CategoryRelativityColumns['tier']=Risk_Tiers\n",
    "\n",
    "protocolMap=CategoryRelativityColumns.filter(['appId','tier','categorySolace'], axis=1)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('../governance/reference/SolaceRMValues.xlsx', mode=\"a\",engine=\"openpyxl\",if_sheet_exists=\"replace\") as writer:protocolMap.to_excel(writer, sheet_name=\"protocolMap\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "413cd85ab13ac62721d0f2c5aa8745784a29b6d09b4bf6a7b76b2766b50fd579"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
